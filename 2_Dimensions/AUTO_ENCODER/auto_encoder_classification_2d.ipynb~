{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Classification of MNIST dataset after dimensionality reduction from 784 to 32 using Auto-Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Accuracy ~ 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN 5005)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import theano\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n",
      "(42000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('/home/vasu/all_projects/ML/t-sne_vs_pca_vs_autoencoder/train.csv')\n",
    "X = np.array(x)\n",
    "x = X[:,1:]\n",
    "y = X[:,0]\n",
    "print x.shape,y.shape\n",
    "X = x.reshape((X.shape[0], 1, 28, 28))\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:136: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 2)\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model('./enc_2d.h5')\n",
    "X_enc = encoder.predict(X)\n",
    "print X_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_enc = (X_enc - X_enc.mean()/X_enc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2) (12000, 2) (30000, 10) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_enc[:30000,:]\n",
    "x_crossval = X_enc[30000:,:]\n",
    "y = np_utils.to_categorical(y)\n",
    "y_train = y[:30000]\n",
    "y_crossval = y[30000:]\n",
    "print x_train.shape,x_crossval.shape,y_train.shape,y_crossval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 16)            48          dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 16)            0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            170         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 10)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 218\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s - loss: 11.0824 - acc: 0.1334 - val_loss: 9.1972 - val_acc: 0.2291\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s - loss: 5.5289 - acc: 0.2268 - val_loss: 2.6851 - val_acc: 0.2620\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s - loss: 2.4004 - acc: 0.2693 - val_loss: 2.2497 - val_acc: 0.3359\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s - loss: 2.1639 - acc: 0.2880 - val_loss: 2.0706 - val_acc: 0.3532\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.9579 - acc: 0.2924 - val_loss: 1.7628 - val_acc: 0.3338\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.8367 - acc: 0.2994 - val_loss: 1.6901 - val_acc: 0.3916\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.7755 - acc: 0.3226 - val_loss: 1.6079 - val_acc: 0.4541\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.7116 - acc: 0.3507 - val_loss: 1.5446 - val_acc: 0.4656\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6857 - acc: 0.3578 - val_loss: 1.5136 - val_acc: 0.4972\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6668 - acc: 0.3670 - val_loss: 1.4882 - val_acc: 0.5102\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6451 - acc: 0.3775 - val_loss: 1.4626 - val_acc: 0.5276\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6294 - acc: 0.3870 - val_loss: 1.4421 - val_acc: 0.5317\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6174 - acc: 0.3907 - val_loss: 1.4470 - val_acc: 0.5565\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.6080 - acc: 0.4020 - val_loss: 1.4239 - val_acc: 0.5507\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5932 - acc: 0.3971 - val_loss: 1.4069 - val_acc: 0.5523\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5797 - acc: 0.4010 - val_loss: 1.4070 - val_acc: 0.5632\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5804 - acc: 0.4083 - val_loss: 1.3761 - val_acc: 0.5565\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5632 - acc: 0.4103 - val_loss: 1.3635 - val_acc: 0.5616\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5597 - acc: 0.4168 - val_loss: 1.3597 - val_acc: 0.5573\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5565 - acc: 0.4193 - val_loss: 1.3376 - val_acc: 0.5597\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5417 - acc: 0.4255 - val_loss: 1.3438 - val_acc: 0.5753\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5432 - acc: 0.4321 - val_loss: 1.3028 - val_acc: 0.5815\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5279 - acc: 0.4429 - val_loss: 1.3019 - val_acc: 0.5874\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5072 - acc: 0.4510 - val_loss: 1.2932 - val_acc: 0.5860\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.5048 - acc: 0.4597 - val_loss: 1.2848 - val_acc: 0.5920\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4990 - acc: 0.4608 - val_loss: 1.2724 - val_acc: 0.5900\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4841 - acc: 0.4643 - val_loss: 1.2647 - val_acc: 0.5965\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4807 - acc: 0.4593 - val_loss: 1.2757 - val_acc: 0.5952\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4744 - acc: 0.4581 - val_loss: 1.2524 - val_acc: 0.5870\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4492 - acc: 0.4554 - val_loss: 1.2576 - val_acc: 0.5818\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4365 - acc: 0.4602 - val_loss: 1.2279 - val_acc: 0.5658\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4256 - acc: 0.4716 - val_loss: 1.2326 - val_acc: 0.5772\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4213 - acc: 0.4748 - val_loss: 1.2122 - val_acc: 0.5730\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3884 - acc: 0.4779 - val_loss: 1.1456 - val_acc: 0.5837\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3752 - acc: 0.4828 - val_loss: 1.1359 - val_acc: 0.5952\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3647 - acc: 0.4869 - val_loss: 1.1485 - val_acc: 0.5892\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3568 - acc: 0.4928 - val_loss: 1.1228 - val_acc: 0.5998\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3558 - acc: 0.4902 - val_loss: 1.1207 - val_acc: 0.5870\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3452 - acc: 0.4995 - val_loss: 1.1214 - val_acc: 0.5909\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3482 - acc: 0.4971 - val_loss: 1.1099 - val_acc: 0.6013\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3378 - acc: 0.4954 - val_loss: 1.1228 - val_acc: 0.5941\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3384 - acc: 0.4954 - val_loss: 1.1105 - val_acc: 0.6131\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3317 - acc: 0.5015 - val_loss: 1.1245 - val_acc: 0.6122\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3306 - acc: 0.5043 - val_loss: 1.1238 - val_acc: 0.5968\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3162 - acc: 0.5104 - val_loss: 1.1015 - val_acc: 0.6217\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3168 - acc: 0.5108 - val_loss: 1.0982 - val_acc: 0.6291\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3149 - acc: 0.5205 - val_loss: 1.1111 - val_acc: 0.6229\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3044 - acc: 0.5164 - val_loss: 1.0918 - val_acc: 0.6121\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.3037 - acc: 0.5126 - val_loss: 1.1011 - val_acc: 0.6144\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2952 - acc: 0.5108 - val_loss: 1.1114 - val_acc: 0.6030\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2999 - acc: 0.5138 - val_loss: 1.0859 - val_acc: 0.6082\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2930 - acc: 0.5199 - val_loss: 1.0914 - val_acc: 0.6195\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2929 - acc: 0.5199 - val_loss: 1.0858 - val_acc: 0.6032\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2801 - acc: 0.5269 - val_loss: 1.0935 - val_acc: 0.6076\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2881 - acc: 0.5258 - val_loss: 1.0782 - val_acc: 0.6094\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2886 - acc: 0.5248 - val_loss: 1.0806 - val_acc: 0.6104\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2811 - acc: 0.5240 - val_loss: 1.0899 - val_acc: 0.6048\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2894 - acc: 0.5265 - val_loss: 1.0833 - val_acc: 0.6130\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2850 - acc: 0.5295 - val_loss: 1.0702 - val_acc: 0.6150\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2775 - acc: 0.5322 - val_loss: 1.0838 - val_acc: 0.6089\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2790 - acc: 0.5309 - val_loss: 1.0841 - val_acc: 0.6071\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2739 - acc: 0.5326 - val_loss: 1.0852 - val_acc: 0.6050\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2770 - acc: 0.5352 - val_loss: 1.0743 - val_acc: 0.6027\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2775 - acc: 0.5350 - val_loss: 1.0891 - val_acc: 0.6019\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2772 - acc: 0.5311 - val_loss: 1.0798 - val_acc: 0.6055\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2743 - acc: 0.5337 - val_loss: 1.0754 - val_acc: 0.6049\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2859 - acc: 0.5325 - val_loss: 1.0695 - val_acc: 0.6032\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2767 - acc: 0.5340 - val_loss: 1.0850 - val_acc: 0.6096\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2753 - acc: 0.5328 - val_loss: 1.0734 - val_acc: 0.6086\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2763 - acc: 0.5359 - val_loss: 1.0765 - val_acc: 0.6138\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2810 - acc: 0.5303 - val_loss: 1.0673 - val_acc: 0.6087\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2773 - acc: 0.5364 - val_loss: 1.0751 - val_acc: 0.6096\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2731 - acc: 0.5335 - val_loss: 1.0726 - val_acc: 0.6123\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2752 - acc: 0.5366 - val_loss: 1.0735 - val_acc: 0.6128\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2806 - acc: 0.5312 - val_loss: 1.0726 - val_acc: 0.6074\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2782 - acc: 0.5292 - val_loss: 1.0763 - val_acc: 0.6056\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2739 - acc: 0.5398 - val_loss: 1.0863 - val_acc: 0.6028\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2777 - acc: 0.5346 - val_loss: 1.0677 - val_acc: 0.6127\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2657 - acc: 0.5370 - val_loss: 1.0607 - val_acc: 0.6202\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2819 - acc: 0.5345 - val_loss: 1.0770 - val_acc: 0.6241\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2750 - acc: 0.5350 - val_loss: 1.0714 - val_acc: 0.6152\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2847 - acc: 0.5304 - val_loss: 1.0809 - val_acc: 0.6159\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2735 - acc: 0.5339 - val_loss: 1.0731 - val_acc: 0.6108\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2717 - acc: 0.5332 - val_loss: 1.0707 - val_acc: 0.6112\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2760 - acc: 0.5327 - val_loss: 1.0608 - val_acc: 0.6281\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2513 - acc: 0.5418 - val_loss: 1.0476 - val_acc: 0.6426\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2498 - acc: 0.5422 - val_loss: 1.0694 - val_acc: 0.6378\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2471 - acc: 0.5445 - val_loss: 1.0410 - val_acc: 0.6513\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2443 - acc: 0.5438 - val_loss: 1.0526 - val_acc: 0.6423\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2407 - acc: 0.5481 - val_loss: 1.0438 - val_acc: 0.6459\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2367 - acc: 0.5474 - val_loss: 1.0402 - val_acc: 0.6458\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2451 - acc: 0.5446 - val_loss: 1.0385 - val_acc: 0.6434\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2474 - acc: 0.5460 - val_loss: 1.0509 - val_acc: 0.6419\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2371 - acc: 0.5478 - val_loss: 1.0321 - val_acc: 0.6437\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2326 - acc: 0.5508 - val_loss: 1.0324 - val_acc: 0.6488\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2391 - acc: 0.5484 - val_loss: 1.0437 - val_acc: 0.6417\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2386 - acc: 0.5450 - val_loss: 1.0362 - val_acc: 0.6455\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2407 - acc: 0.5454 - val_loss: 1.0369 - val_acc: 0.6507\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2435 - acc: 0.5450 - val_loss: 1.0453 - val_acc: 0.6477\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2347 - acc: 0.5473 - val_loss: 1.0379 - val_acc: 0.6457\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,y_train,\n",
    "                 nb_epoch = 100,\n",
    "                 shuffle = True,\n",
    "                 batch_size = 256,\n",
    "                 validation_data=(x_crossval, y_crossval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMdyJiDKI4U5ElEH/H5kRdxN/iNeSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fd503a350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['val_loss'], color ='b')\n",
    "plt.plot(hist.history['loss'], color='r')\n",
    "plt.plot(hist.history['val_acc'], color ='black')\n",
    "plt.plot(hist.history['acc'], color ='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
