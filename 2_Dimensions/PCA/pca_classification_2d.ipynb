{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Classification of MNIST dataset after dimensionality reduction from 784 to 2 using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Accuracy ~ 47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN 5005)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import theano\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Activation, Dropout\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n",
      "(42000, 784) (30000,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('/home/chiransh/all_projects/ML/t-sne_vs_pca_vs_autoencoder/train.csv')\n",
    "X = np.array(x)\n",
    "x = X[:,1:]\n",
    "y = X[:,0]\n",
    "print x.shape,y.shape\n",
    "\n",
    "y_train = y[:30000]\n",
    "y_crossval = y[30000:]\n",
    "print x.shape,y_train.shape,y_crossval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = (x - x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2) (12000, 2) (30000, 10) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "X = pca.fit_transform(x)\n",
    "#X_crossval = pca.fit_transform(x_crossval)\n",
    "X_train = X[:30000,:]\n",
    "X_crossval = X[30000:,:]\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_crossval = np_utils.to_categorical(y_crossval)\n",
    "print X_train.shape, X_crossval.shape, Y_train.shape, Y_crossval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_3 (Dense)                  (None, 16)            48          dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 16)            0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            170         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10)            0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 218\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 4s - loss: 3.1513 - acc: 0.1734 - val_loss: 1.9786 - val_acc: 0.2578\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 4s - loss: 2.0605 - acc: 0.2757 - val_loss: 1.5876 - val_acc: 0.3913\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 3s - loss: 1.8000 - acc: 0.3290 - val_loss: 1.5116 - val_acc: 0.4046\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 3s - loss: 1.6969 - acc: 0.3455 - val_loss: 1.4755 - val_acc: 0.4223\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.6433 - acc: 0.3559 - val_loss: 1.4551 - val_acc: 0.4248\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.6002 - acc: 0.3695 - val_loss: 1.4371 - val_acc: 0.4301\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5787 - acc: 0.3747 - val_loss: 1.4231 - val_acc: 0.4312\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5524 - acc: 0.3788 - val_loss: 1.4110 - val_acc: 0.4343\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5426 - acc: 0.3803 - val_loss: 1.4006 - val_acc: 0.4371\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5276 - acc: 0.3899 - val_loss: 1.3942 - val_acc: 0.4372\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5179 - acc: 0.3963 - val_loss: 1.3871 - val_acc: 0.4383\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5103 - acc: 0.4025 - val_loss: 1.3825 - val_acc: 0.4382\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.5030 - acc: 0.4011 - val_loss: 1.3791 - val_acc: 0.4417\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4986 - acc: 0.4049 - val_loss: 1.3771 - val_acc: 0.4413\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4956 - acc: 0.4052 - val_loss: 1.3731 - val_acc: 0.4417\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 3s - loss: 1.4929 - acc: 0.4077 - val_loss: 1.3708 - val_acc: 0.4427\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 3s - loss: 1.4811 - acc: 0.4122 - val_loss: 1.3683 - val_acc: 0.4458\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 4s - loss: 1.4816 - acc: 0.4138 - val_loss: 1.3661 - val_acc: 0.4445\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4831 - acc: 0.4148 - val_loss: 1.3652 - val_acc: 0.4467\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4761 - acc: 0.4131 - val_loss: 1.3628 - val_acc: 0.4476\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4736 - acc: 0.4158 - val_loss: 1.3599 - val_acc: 0.4448\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4712 - acc: 0.4130 - val_loss: 1.3591 - val_acc: 0.4469\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4699 - acc: 0.4116 - val_loss: 1.3581 - val_acc: 0.4487\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4692 - acc: 0.4182 - val_loss: 1.3578 - val_acc: 0.4482\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4704 - acc: 0.4148 - val_loss: 1.3564 - val_acc: 0.4488\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4652 - acc: 0.4203 - val_loss: 1.3553 - val_acc: 0.4488\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4640 - acc: 0.4181 - val_loss: 1.3531 - val_acc: 0.4486\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 5s - loss: 1.4589 - acc: 0.4199 - val_loss: 1.3530 - val_acc: 0.4521\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 4s - loss: 1.4615 - acc: 0.4158 - val_loss: 1.3514 - val_acc: 0.4529\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 2s - loss: 1.4599 - acc: 0.4181 - val_loss: 1.3511 - val_acc: 0.4530\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4581 - acc: 0.4229 - val_loss: 1.3501 - val_acc: 0.4561\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4526 - acc: 0.4186 - val_loss: 1.3461 - val_acc: 0.4533\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4527 - acc: 0.4206 - val_loss: 1.3462 - val_acc: 0.4489\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4546 - acc: 0.4213 - val_loss: 1.3449 - val_acc: 0.4531\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 1s - loss: 1.4499 - acc: 0.4212 - val_loss: 1.3443 - val_acc: 0.4538\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4524 - acc: 0.4197 - val_loss: 1.3439 - val_acc: 0.4542\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4509 - acc: 0.4203 - val_loss: 1.3423 - val_acc: 0.4552\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4512 - acc: 0.4224 - val_loss: 1.3415 - val_acc: 0.4563\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4496 - acc: 0.4217 - val_loss: 1.3419 - val_acc: 0.4558\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4498 - acc: 0.4202 - val_loss: 1.3402 - val_acc: 0.4566\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4486 - acc: 0.4224 - val_loss: 1.3406 - val_acc: 0.4539\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4465 - acc: 0.4240 - val_loss: 1.3387 - val_acc: 0.4530\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4469 - acc: 0.4250 - val_loss: 1.3399 - val_acc: 0.4581\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4489 - acc: 0.4208 - val_loss: 1.3395 - val_acc: 0.4602\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4440 - acc: 0.4271 - val_loss: 1.3376 - val_acc: 0.4586\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4446 - acc: 0.4233 - val_loss: 1.3384 - val_acc: 0.4557\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4418 - acc: 0.4254 - val_loss: 1.3381 - val_acc: 0.4589\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4446 - acc: 0.4218 - val_loss: 1.3381 - val_acc: 0.4601\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4432 - acc: 0.4226 - val_loss: 1.3373 - val_acc: 0.4593\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4445 - acc: 0.4279 - val_loss: 1.3364 - val_acc: 0.4567\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4417 - acc: 0.4241 - val_loss: 1.3365 - val_acc: 0.4582\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4455 - acc: 0.4237 - val_loss: 1.3377 - val_acc: 0.4620\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4427 - acc: 0.4249 - val_loss: 1.3356 - val_acc: 0.4588\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4402 - acc: 0.4264 - val_loss: 1.3361 - val_acc: 0.4587\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4375 - acc: 0.4261 - val_loss: 1.3356 - val_acc: 0.4601\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4385 - acc: 0.4252 - val_loss: 1.3347 - val_acc: 0.4611\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4395 - acc: 0.4271 - val_loss: 1.3346 - val_acc: 0.4594\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 1s - loss: 1.4426 - acc: 0.4235 - val_loss: 1.3356 - val_acc: 0.4630\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4392 - acc: 0.4253 - val_loss: 1.3349 - val_acc: 0.4576\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4417 - acc: 0.4273 - val_loss: 1.3349 - val_acc: 0.4600\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4389 - acc: 0.4245 - val_loss: 1.3342 - val_acc: 0.4616\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4374 - acc: 0.4267 - val_loss: 1.3341 - val_acc: 0.4569\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4375 - acc: 0.4269 - val_loss: 1.3353 - val_acc: 0.4595\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4379 - acc: 0.4245 - val_loss: 1.3345 - val_acc: 0.4618\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4388 - acc: 0.4254 - val_loss: 1.3339 - val_acc: 0.4608\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4396 - acc: 0.4263 - val_loss: 1.3356 - val_acc: 0.4559\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4364 - acc: 0.4265 - val_loss: 1.3330 - val_acc: 0.4602\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4414 - acc: 0.4249 - val_loss: 1.3335 - val_acc: 0.4584\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4390 - acc: 0.4272 - val_loss: 1.3344 - val_acc: 0.4630\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4365 - acc: 0.4260 - val_loss: 1.3330 - val_acc: 0.4612\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4344 - acc: 0.4280 - val_loss: 1.3331 - val_acc: 0.4578\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4359 - acc: 0.4291 - val_loss: 1.3321 - val_acc: 0.4605\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4404 - acc: 0.4259 - val_loss: 1.3338 - val_acc: 0.4587\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4368 - acc: 0.4269 - val_loss: 1.3322 - val_acc: 0.4614\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4387 - acc: 0.4234 - val_loss: 1.3329 - val_acc: 0.4604\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4353 - acc: 0.4265 - val_loss: 1.3334 - val_acc: 0.4634\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4389 - acc: 0.4261 - val_loss: 1.3322 - val_acc: 0.4614\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4367 - acc: 0.4265 - val_loss: 1.3323 - val_acc: 0.4613\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4361 - acc: 0.4265 - val_loss: 1.3311 - val_acc: 0.4602\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4392 - acc: 0.4273 - val_loss: 1.3320 - val_acc: 0.4638\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4360 - acc: 0.4283 - val_loss: 1.3311 - val_acc: 0.4620\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4387 - acc: 0.4261 - val_loss: 1.3318 - val_acc: 0.4605\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4355 - acc: 0.4279 - val_loss: 1.3307 - val_acc: 0.4615\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4365 - acc: 0.4282 - val_loss: 1.3318 - val_acc: 0.4625\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4362 - acc: 0.4272 - val_loss: 1.3307 - val_acc: 0.4627\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4397 - acc: 0.4261 - val_loss: 1.3314 - val_acc: 0.4608\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4356 - acc: 0.4266 - val_loss: 1.3307 - val_acc: 0.4603\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4346 - acc: 0.4243 - val_loss: 1.3318 - val_acc: 0.4630\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4372 - acc: 0.4246 - val_loss: 1.3301 - val_acc: 0.4613\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4366 - acc: 0.4270 - val_loss: 1.3295 - val_acc: 0.4611\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4340 - acc: 0.4283 - val_loss: 1.3302 - val_acc: 0.4618\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4353 - acc: 0.4260 - val_loss: 1.3303 - val_acc: 0.4635\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4358 - acc: 0.4257 - val_loss: 1.3303 - val_acc: 0.4615\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4345 - acc: 0.4299 - val_loss: 1.3300 - val_acc: 0.4611\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4349 - acc: 0.4264 - val_loss: 1.3303 - val_acc: 0.4621\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4355 - acc: 0.4275 - val_loss: 1.3300 - val_acc: 0.4625\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4367 - acc: 0.4262 - val_loss: 1.3293 - val_acc: 0.4614\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4335 - acc: 0.4265 - val_loss: 1.3297 - val_acc: 0.4612\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4353 - acc: 0.4286 - val_loss: 1.3302 - val_acc: 0.4612\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.4330 - acc: 0.4271 - val_loss: 1.3303 - val_acc: 0.4645\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "                nb_epoch=100,\n",
    "                shuffle=True,\n",
    "                batch_size=256,\n",
    "                validation_data=(X_crossval, Y_crossval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f008d05f510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['val_loss'], color ='b')\n",
    "plt.plot(hist.history['loss'], color='r')\n",
    "plt.plot(hist.history['val_acc'], color ='black')\n",
    "plt.plot(hist.history['acc'], color ='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
