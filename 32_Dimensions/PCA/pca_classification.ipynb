{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Classification of MNIST dataset after dimensionality reduction from 784 32 using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Accuracy ~ 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN 5005)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import theano\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Activation, Dropout\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n",
      "(42000, 784) (30000,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('./train.csv')\n",
    "X = np.array(x)\n",
    "x = X[:,1:]\n",
    "y = X[:,0]\n",
    "print x.shape,y.shape\n",
    "\n",
    "y_train = y[:30000]\n",
    "y_crossval = y[30000:]\n",
    "print x.shape,y_train.shape,y_crossval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train = (x_train - x_train.mean())/x_train.std()\n",
    "x = (x - x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 32) (12000, 32) (30000, 10) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=32)\n",
    "\n",
    "X = pca.fit_transform(x)\n",
    "#X_crossval = pca.fit_transform(x_crossval)\n",
    "X_train = X[:30000,:]\n",
    "X_crossval = X[30000:,:]\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_crossval = np_utils.to_categorical(y_crossval)\n",
    "print X_train.shape, X_crossval.shape, Y_train.shape, Y_crossval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 16)            528         dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 16)            0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            170         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 10)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 698\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s - loss: 3.2418 - acc: 0.2373 - val_loss: 1.5448 - val_acc: 0.5002\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.7403 - acc: 0.4552 - val_loss: 0.9936 - val_acc: 0.7087\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.2838 - acc: 0.5827 - val_loss: 0.7548 - val_acc: 0.7965\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s - loss: 1.0693 - acc: 0.6486 - val_loss: 0.6246 - val_acc: 0.8349\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.9329 - acc: 0.6918 - val_loss: 0.5440 - val_acc: 0.8572\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.8714 - acc: 0.7126 - val_loss: 0.4961 - val_acc: 0.8674\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.8251 - acc: 0.7254 - val_loss: 0.4654 - val_acc: 0.8728\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7866 - acc: 0.7406 - val_loss: 0.4381 - val_acc: 0.8793\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7606 - acc: 0.7478 - val_loss: 0.4217 - val_acc: 0.8828\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7415 - acc: 0.7532 - val_loss: 0.4093 - val_acc: 0.8863\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7232 - acc: 0.7612 - val_loss: 0.3983 - val_acc: 0.8886\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7195 - acc: 0.7570 - val_loss: 0.3907 - val_acc: 0.8913\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.7063 - acc: 0.7628 - val_loss: 0.3846 - val_acc: 0.8930\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6925 - acc: 0.7682 - val_loss: 0.3772 - val_acc: 0.8937\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6823 - acc: 0.7714 - val_loss: 0.3721 - val_acc: 0.8947\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6769 - acc: 0.7739 - val_loss: 0.3666 - val_acc: 0.8959\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6766 - acc: 0.7709 - val_loss: 0.3634 - val_acc: 0.8971\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6630 - acc: 0.7758 - val_loss: 0.3594 - val_acc: 0.8969\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6670 - acc: 0.7738 - val_loss: 0.3578 - val_acc: 0.8974\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6549 - acc: 0.7779 - val_loss: 0.3543 - val_acc: 0.8975\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6575 - acc: 0.7782 - val_loss: 0.3520 - val_acc: 0.8978\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6478 - acc: 0.7776 - val_loss: 0.3482 - val_acc: 0.8991\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6432 - acc: 0.7819 - val_loss: 0.3453 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6449 - acc: 0.7804 - val_loss: 0.3431 - val_acc: 0.9013\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6410 - acc: 0.7827 - val_loss: 0.3412 - val_acc: 0.9015\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6366 - acc: 0.7840 - val_loss: 0.3394 - val_acc: 0.9023\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6319 - acc: 0.7861 - val_loss: 0.3360 - val_acc: 0.9017\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6346 - acc: 0.7854 - val_loss: 0.3359 - val_acc: 0.9021\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6248 - acc: 0.7899 - val_loss: 0.3314 - val_acc: 0.9035\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6274 - acc: 0.7876 - val_loss: 0.3305 - val_acc: 0.9036\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6310 - acc: 0.7858 - val_loss: 0.3291 - val_acc: 0.9043\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6274 - acc: 0.7886 - val_loss: 0.3283 - val_acc: 0.9047\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6290 - acc: 0.7849 - val_loss: 0.3275 - val_acc: 0.9044\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6298 - acc: 0.7866 - val_loss: 0.3265 - val_acc: 0.9052\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6160 - acc: 0.7883 - val_loss: 0.3238 - val_acc: 0.9048\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6208 - acc: 0.7892 - val_loss: 0.3231 - val_acc: 0.9055\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6179 - acc: 0.7906 - val_loss: 0.3230 - val_acc: 0.9063\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6200 - acc: 0.7878 - val_loss: 0.3216 - val_acc: 0.9058\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6211 - acc: 0.7898 - val_loss: 0.3211 - val_acc: 0.9053\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6163 - acc: 0.7902 - val_loss: 0.3198 - val_acc: 0.9049\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6138 - acc: 0.7916 - val_loss: 0.3183 - val_acc: 0.9064\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6148 - acc: 0.7935 - val_loss: 0.3175 - val_acc: 0.9067\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6206 - acc: 0.7908 - val_loss: 0.3178 - val_acc: 0.9061\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6144 - acc: 0.7888 - val_loss: 0.3178 - val_acc: 0.9068\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6174 - acc: 0.7904 - val_loss: 0.3155 - val_acc: 0.9066\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6172 - acc: 0.7877 - val_loss: 0.3165 - val_acc: 0.9081\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6120 - acc: 0.7921 - val_loss: 0.3152 - val_acc: 0.9079\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6135 - acc: 0.7914 - val_loss: 0.3151 - val_acc: 0.9072\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6054 - acc: 0.7943 - val_loss: 0.3130 - val_acc: 0.9084\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6093 - acc: 0.7971 - val_loss: 0.3116 - val_acc: 0.9096\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6164 - acc: 0.7898 - val_loss: 0.3128 - val_acc: 0.9100\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6049 - acc: 0.7951 - val_loss: 0.3108 - val_acc: 0.9094\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6087 - acc: 0.7917 - val_loss: 0.3109 - val_acc: 0.9087\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6061 - acc: 0.7942 - val_loss: 0.3105 - val_acc: 0.9097\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6056 - acc: 0.7920 - val_loss: 0.3117 - val_acc: 0.9096\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6036 - acc: 0.7941 - val_loss: 0.3090 - val_acc: 0.9092\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6123 - acc: 0.7912 - val_loss: 0.3102 - val_acc: 0.9103\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6062 - acc: 0.7927 - val_loss: 0.3100 - val_acc: 0.9098\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6050 - acc: 0.7950 - val_loss: 0.3085 - val_acc: 0.9108\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6023 - acc: 0.7967 - val_loss: 0.3094 - val_acc: 0.9094\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6033 - acc: 0.7934 - val_loss: 0.3082 - val_acc: 0.9098\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5972 - acc: 0.7963 - val_loss: 0.3075 - val_acc: 0.9093\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5995 - acc: 0.7950 - val_loss: 0.3070 - val_acc: 0.9096\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5972 - acc: 0.7961 - val_loss: 0.3071 - val_acc: 0.9101\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6024 - acc: 0.7926 - val_loss: 0.3081 - val_acc: 0.9089\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6102 - acc: 0.7915 - val_loss: 0.3066 - val_acc: 0.9112\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6058 - acc: 0.7942 - val_loss: 0.3070 - val_acc: 0.9103\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5971 - acc: 0.7936 - val_loss: 0.3081 - val_acc: 0.9100\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5979 - acc: 0.7948 - val_loss: 0.3066 - val_acc: 0.9096\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6015 - acc: 0.7945 - val_loss: 0.3055 - val_acc: 0.9118\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5993 - acc: 0.7954 - val_loss: 0.3066 - val_acc: 0.9109\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6008 - acc: 0.7964 - val_loss: 0.3059 - val_acc: 0.9118\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.6007 - acc: 0.7962 - val_loss: 0.3040 - val_acc: 0.9106\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5990 - acc: 0.7929 - val_loss: 0.3057 - val_acc: 0.9098\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5956 - acc: 0.7994 - val_loss: 0.3071 - val_acc: 0.9090\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5985 - acc: 0.7962 - val_loss: 0.3072 - val_acc: 0.9105\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5956 - acc: 0.7985 - val_loss: 0.3047 - val_acc: 0.9112\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5956 - acc: 0.7998 - val_loss: 0.3039 - val_acc: 0.9115\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5915 - acc: 0.8020 - val_loss: 0.3047 - val_acc: 0.9103\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5954 - acc: 0.7952 - val_loss: 0.3049 - val_acc: 0.9109\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5934 - acc: 0.7994 - val_loss: 0.3032 - val_acc: 0.9112\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5946 - acc: 0.7957 - val_loss: 0.3047 - val_acc: 0.9109\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5942 - acc: 0.7989 - val_loss: 0.3031 - val_acc: 0.9113\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5926 - acc: 0.8008 - val_loss: 0.3027 - val_acc: 0.9120\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5944 - acc: 0.7994 - val_loss: 0.3026 - val_acc: 0.9127\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5977 - acc: 0.7991 - val_loss: 0.3043 - val_acc: 0.9112\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5923 - acc: 0.7978 - val_loss: 0.3036 - val_acc: 0.9107\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5886 - acc: 0.7997 - val_loss: 0.3022 - val_acc: 0.9113\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5917 - acc: 0.7978 - val_loss: 0.3031 - val_acc: 0.9110\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5904 - acc: 0.8021 - val_loss: 0.3031 - val_acc: 0.9113\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5918 - acc: 0.7995 - val_loss: 0.3033 - val_acc: 0.9121\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5899 - acc: 0.8008 - val_loss: 0.3030 - val_acc: 0.9128\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5876 - acc: 0.8004 - val_loss: 0.3038 - val_acc: 0.9112\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5881 - acc: 0.7975 - val_loss: 0.3023 - val_acc: 0.9120\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5871 - acc: 0.8007 - val_loss: 0.3010 - val_acc: 0.9133\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5897 - acc: 0.7997 - val_loss: 0.3017 - val_acc: 0.9122\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5956 - acc: 0.8002 - val_loss: 0.3011 - val_acc: 0.9124\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5915 - acc: 0.7993 - val_loss: 0.3023 - val_acc: 0.9121\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5898 - acc: 0.8015 - val_loss: 0.3024 - val_acc: 0.9119\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s - loss: 0.5886 - acc: 0.7990 - val_loss: 0.3014 - val_acc: 0.9125\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "                nb_epoch=100,\n",
    "                shuffle=True,\n",
    "                batch_size=256,\n",
    "                validation_data=(X_crossval, Y_crossval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkFOgFxEJuf8PwDxPVZm6ikcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47494a5f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['val_loss'], color ='b')\n",
    "plt.plot(hist.history['loss'], color='r')\n",
    "plt.plot(hist.history['val_acc'], color ='black')\n",
    "plt.plot(hist.history['acc'], color ='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
